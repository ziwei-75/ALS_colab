{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import pyfaidx\n",
    "sys.path.append(\"/oak/stanford/groups/akundaje/ziwei75/HTRANet/HTRANet/mpra/src/train\")\n",
    "sys.path.append(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/script/2023_8_21_shap_score\")\n",
    "import one_hot\n",
    "import shap_utils\n",
    "import shap\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "differential_regions=pd.read_csv(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/sod1_project/differential_regions_alpha_MNs/differentialRegions.bed\",\\\n",
    "                                 sep='\\t',\\\n",
    "                                header=None)\n",
    "\n",
    "genome=\"/oak/stanford/groups/akundaje/ziwei75/atac_seq_pipeline/mm10/mm10_no_alt_analysis_set_ENCODE.fasta\"\n",
    "genome = pyfaidx.Fasta(genome)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "flank_size=2114//2\n",
    "for i, row in differential_regions[:10].iterrows():\n",
    "    chromo, start, end = row\n",
    "    center = (start+end)//2\n",
    "    start = center - flank_size \n",
    "    end = center + flank_size\n",
    "    seq = genome[chromo][start:end].seq\n",
    "    sequences += [seq]   \n",
    "sequences=one_hot.dna_to_one_hot(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 01:51:26.410054: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 01:51:27.249812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10553 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "cell_type=\"alpha_control\"\n",
    "fold_number=0\n",
    "model = \"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/models/2023_8_10/%s/fold%s/models/chrombpnet_nobias.h5\"%(cell_type,fold_number)\n",
    "model = load_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(model, seqs, profile_or_counts):\n",
    "    print(\"Seqs dimension : {}\".format(seqs.shape))\n",
    "\n",
    "    outlen = model.output_shape[0][1]\n",
    "\n",
    "    profile_model_input = model.input\n",
    "    profile_input = seqs\n",
    "    counts_model_input = model.input\n",
    "    counts_input = seqs\n",
    "\n",
    "    if profile_or_counts == \"counts\":\n",
    "        profile_model_counts_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "            (counts_model_input, tf.reduce_sum(model.outputs[1], axis=-1)),\n",
    "            shap_utils.shuffle_several_times,\n",
    "            combine_mult_and_diffref=shap_utils.combine_mult_and_diffref)\n",
    "\n",
    "        print(\"Generating 'counts' shap scores\")\n",
    "        counts_shap_scores = profile_model_counts_explainer.shap_values(\n",
    "            counts_input, progress_message=100)\n",
    "        return counts_shap_scores\n",
    "        \n",
    "    if profile_or_counts == \"profile\":\n",
    "        weightedsum_meannormed_logits = shap_utils.get_weightedsum_meannormed_logits(model)\n",
    "        profile_model_profile_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "            (profile_model_input, weightedsum_meannormed_logits),\n",
    "            shap_utils.shuffle_several_times,\n",
    "            combine_mult_and_diffref=shap_utils.combine_mult_and_diffref)\n",
    "\n",
    "        print(\"Generating 'profile' shap scores\")\n",
    "        profile_shap_scores = profile_model_profile_explainer.shap_values(\n",
    "            profile_input, progress_message=100)    \n",
    "        return profile_shap_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seqs dimension : (10, 2114, 4)\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'counts' shap scores\n",
      "Done 0 examples of 10\n",
      "Seqs dimension : (10, 2114, 4)\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  StopGradient used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'profile' shap scores\n",
      "Done 0 examples of 10\n"
     ]
    }
   ],
   "source": [
    "count_shap_score = interpret(model, sequences, \"counts\")\n",
    "profile_shap_score = interpret(model, sequences, \"profile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_shap_file=\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_fold%s_count_shap.npz\"%(cell_type,fold_number)\n",
    "profile_shap_file=\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_fold%s_profile_shap.npz\"%(cell_type,fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(count_shap_file,count_shap_score)\n",
    "np.savez(profile_shap_file,profile_shap_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2114, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(count_shap_file)['arr_0'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write shap score to bigwig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "averaged_shap_dict = {}\n",
    "for cell_type in [\"alpha_control\",\"alpha_early_disease\",\"alpha_midLate_disease\",\"panGamma_control\"]:\n",
    "    shap_score_list = []\n",
    "    for fold_number in range(5):\n",
    "        shap_score = \"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_fold%s_count_shap.npz\"%(cell_type,fold_number)\n",
    "        shap_score = np.load(shap_score)['arr_0']\n",
    "        shap_score_list += [shap_score]\n",
    "    a_shap_score = np.average(np.stack(shap_score_list),axis=0)\n",
    "    averaged_shap_dict[cell_type] = a_shap_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyfaidx\n",
    "import sys\n",
    "sys.path.append(\"/oak/stanford/groups/akundaje/ziwei75/HTRANet/HTRANet/mpra/src/train\")\n",
    "sys.path.append(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/script/2023_8_21_shap_score\")\n",
    "import one_hot\n",
    "differential_regions=pd.read_csv(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/sod1_project/differential_regions_alpha_MNs/differentialRegions.bed\",\\\n",
    "                                 sep='\\t',\\\n",
    "                                header=None)\n",
    "genome=\"/oak/stanford/groups/akundaje/ziwei75/atac_seq_pipeline/mm10/mm10_no_alt_analysis_set_ENCODE.fasta\"\n",
    "genome = pyfaidx.Fasta(genome)\n",
    "\n",
    "coords = []\n",
    "sequences = []\n",
    "flank_size=2114//2\n",
    "for i, row in differential_regions.iterrows():\n",
    "    chromo, start, end = row\n",
    "    center = (start+end)//2\n",
    "    start = center - flank_size \n",
    "    end = center + flank_size\n",
    "    coords += [[chromo, start, end]]\n",
    "    seq = genome[chromo][start:end].seq\n",
    "    sequences += [seq]   \n",
    "sequences=one_hot.dna_to_one_hot(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_list = list(averaged_shap_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyBigWig\n",
    "def read_chrom_sizes(fname):\n",
    "    with open(fname) as f:\n",
    "        gs = [x.strip().split('\\t') for x in f]\n",
    "    gs = [(x[0], int(x[1])) for x in gs if len(x)==2]\n",
    " \n",
    "    for g in gs.copy():\n",
    "        if \"random\" in g[0] or \"GL\" in g[0] or 'chrUn_JH584304' in g[0]:\n",
    "            gs.remove(g)\n",
    "    gs.sort(key=lambda x: x[0])\n",
    "    return gs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in cell_type_list:\n",
    "    chrom_sizes=\"/oak/stanford/groups/akundaje/ziwei75/atac_seq_pipeline/mm10/mm10_no_alt.chrom.sizes.tsv\"\n",
    "    bw_out=\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_count_shap_score.bw\"%cell_type\n",
    "    gs = read_chrom_sizes(chrom_sizes)\n",
    "    bw = pyBigWig.open(bw_out, 'w')\n",
    "    bw.addHeader(gs)\n",
    "    \n",
    "    shap_score = averaged_shap_dict[cell_type]\n",
    "    \n",
    "    for i in range(len(coords)):\n",
    "        chromo, start, end = coords[i]\n",
    "        start_list = np.array(list(range(start,end)))\n",
    "        end_list = start_list + 1\n",
    "        c_list = np.array([chromo for i in range(len(start_list))])\n",
    "        value = shap_score[i]\n",
    "        seq = sequences[i]\n",
    "        value = np.sum(value * seq,axis=1)\n",
    "\n",
    "        bw.addEntries(c_list,\n",
    "                   start_list,\n",
    "                   ends = end_list,\n",
    "                   values=np.asarray(value))\n",
    "\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating prediction bigwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "sequences = []\n",
    "flank_size=2114//2\n",
    "for i, row in differential_regions.iterrows():\n",
    "    chromo, start, end = row\n",
    "    center = (start+end)//2\n",
    "    start = center - flank_size \n",
    "    end = center + flank_size\n",
    "    coords += [[chromo, start, end]]\n",
    "    seq = genome[chromo][start:end].seq\n",
    "    sequences += [seq]   \n",
    "sequences=one_hot.dna_to_one_hot(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 00:07:13.915011: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 00:07:14.691865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10553 MB memory:  -> device: 0, name: NVIDIA TITAN V, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/ziwei75/anaconda3/envs/enhancer_promoter_model/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "2023-08-23 00:07:15.835081: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "def softmax(x, temp=1):\n",
    "    norm_x = x - np.mean(x,axis=1, keepdims=True)\n",
    "    return np.exp(temp*norm_x)/np.sum(np.exp(temp*norm_x), axis=1, keepdims=True)\n",
    "\n",
    "for cell_type in [\"alpha_control\",\"alpha_early_disease\",\"alpha_midLate_disease\",\"panGamma_control\"]:\n",
    "    total_profile_predictions = []\n",
    "    total_count_predictions = []\n",
    "    for fold_number in range(5):\n",
    "        model = \"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/models/2023_8_10/%s/fold%s/models/chrombpnet_nobias.h5\"%(cell_type,fold_number)\n",
    "        model = load_model(model)\n",
    "        profile_predictions, count_predictions = model.predict(sequences,verbose=True)\n",
    "        total_profile_predictions += [softmax(profile_predictions)]\n",
    "        total_count_predictions += [count_predictions]\n",
    "    a_profile_prediction = np.average(np.stack(total_profile_predictions),axis=0)  \n",
    "    a_count_prediction = np.average(np.stack(total_count_predictions),axis=0)  \n",
    "    np.savez(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_profile_predictions.npz\"%cell_type,a_profile_prediction)\n",
    "    np.savez(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_count_predictions.npz\"%cell_type,a_count_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyfaidx\n",
    "import sys\n",
    "sys.path.append(\"/oak/stanford/groups/akundaje/ziwei75/HTRANet/HTRANet/mpra/src/train\")\n",
    "sys.path.append(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/script/2023_8_21_shap_score\")\n",
    "import one_hot\n",
    "differential_regions=pd.read_csv(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/sod1_project/differential_regions_alpha_MNs/differentialRegions.bed\",\\\n",
    "                                 sep='\\t',\\\n",
    "                                header=None)\n",
    "\n",
    "coords = []\n",
    "flank_size=1000//2\n",
    "for i, row in differential_regions.iterrows():\n",
    "    chromo, start, end = row\n",
    "    center = (start+end)//2\n",
    "    start = center - flank_size \n",
    "    end = center + flank_size\n",
    "    coords += [[chromo, start, end]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in [\"alpha_control\",\"alpha_early_disease\",\"alpha_midLate_disease\",\"panGamma_control\"]:\n",
    "    chrom_sizes=\"/oak/stanford/groups/akundaje/ziwei75/atac_seq_pipeline/mm10/mm10_no_alt.chrom.sizes.tsv\"\n",
    "    bw_out=\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_profile_prediction.bw\"%cell_type\n",
    "    gs = read_chrom_sizes(chrom_sizes)\n",
    "    bw = pyBigWig.open(bw_out, 'w')\n",
    "    bw.addHeader(gs)\n",
    "    \n",
    "    corrected_profile = np.load(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_profile_predictions.npz\"%cell_type)['arr_0']\n",
    "    counts = np.load(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/output/differential_region/%s_count_predictions.npz\"%cell_type)['arr_0']\n",
    "    for i in range(len(coords)):\n",
    "        chromo, start, end = coords[i]\n",
    "        start_list = np.array(list(range(start,end)))\n",
    "        end_list = start_list + 1\n",
    "        c_list = np.array([chromo for i in range(len(start_list))])\n",
    "        value = corrected_profile[i] * np.exp(counts[i])\n",
    "\n",
    "        bw.addEntries(c_list,\n",
    "                   start_list,\n",
    "                   ends = end_list,\n",
    "                   values=np.asarray(value))\n",
    "\n",
    "    bw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "differential_peak = pd.read_csv(\"/oak/stanford/groups/akundaje/ziwei75/ALS_colab/sod1_project/differential_regions_alpha_MNs/differentialRegions_Log2FC_FDR.bed\",\\\n",
    "           sep='\\t',\\\n",
    "           header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>chr1</td>\n",
       "      <td>31300924</td>\n",
       "      <td>31301425</td>\n",
       "      <td>7.197307</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14529</th>\n",
       "      <td>chr4</td>\n",
       "      <td>85069085</td>\n",
       "      <td>85069586</td>\n",
       "      <td>6.210727</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>chr10</td>\n",
       "      <td>34464248</td>\n",
       "      <td>34464749</td>\n",
       "      <td>5.411800</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>chr11</td>\n",
       "      <td>82483568</td>\n",
       "      <td>82484069</td>\n",
       "      <td>5.089432</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10448</th>\n",
       "      <td>chr19</td>\n",
       "      <td>6876901</td>\n",
       "      <td>6877402</td>\n",
       "      <td>4.967117</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>chr12</td>\n",
       "      <td>38171387</td>\n",
       "      <td>38171888</td>\n",
       "      <td>-3.900997</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>chr11</td>\n",
       "      <td>55412808</td>\n",
       "      <td>55413309</td>\n",
       "      <td>-3.976932</td>\n",
       "      <td>0.000811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15588</th>\n",
       "      <td>chr5</td>\n",
       "      <td>21625227</td>\n",
       "      <td>21625728</td>\n",
       "      <td>-3.993568</td>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10847</th>\n",
       "      <td>chr19</td>\n",
       "      <td>48963116</td>\n",
       "      <td>48963617</td>\n",
       "      <td>-4.132064</td>\n",
       "      <td>0.001646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15675</th>\n",
       "      <td>chr5</td>\n",
       "      <td>27900950</td>\n",
       "      <td>27901451</td>\n",
       "      <td>-4.427355</td>\n",
       "      <td>0.008477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22153 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "136     chr1  31300924  31301425  7.197307  0.000000\n",
       "14529   chr4  85069085  85069586  6.210727  0.000000\n",
       "1874   chr10  34464248  34464749  5.411800  0.000001\n",
       "3499   chr11  82483568  82484069  5.089432  0.000014\n",
       "10448  chr19   6876901   6877402  4.967117  0.000009\n",
       "...      ...       ...       ...       ...       ...\n",
       "4359   chr12  38171387  38171888 -3.900997  0.000105\n",
       "3144   chr11  55412808  55413309 -3.976932  0.000811\n",
       "15588   chr5  21625227  21625728 -3.993568  0.000169\n",
       "10847  chr19  48963116  48963617 -4.132064  0.001646\n",
       "15675   chr5  27900950  27901451 -4.427355  0.008477\n",
       "\n",
       "[22153 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "differential_peak[differential_peak[4] <=0.1].sort_values(3,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhancer_promoter_model",
   "language": "python",
   "name": "enhancer_promoter_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
